{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from etl import enron_parse\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download email.csv from here: https://www.kaggle.com/wcukierski/enron-email-dataset\n",
    "\n",
    "make sure to put it in the same directory as where NLU-email-title folder is at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Dataset\n",
    "\n",
    "Total 517401 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517401"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsed Dataset (Text)\n",
    "- data originally 517401 entires\n",
    "- reduce to only original emails (now total 293291 entries)\n",
    "- cleaned the body to only have raw text left\n",
    "- droped nan titles (276253)\n",
    "- droped duplicated values (128706)\n",
    "- droped those with 're:' or 'fw:' in the title (111044)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 517401/517401 [04:47<00:00, 1800.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# parsed_All = enron_parse.parse_all(df.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(parsed_All).loc[:,['Subject','Body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('ALL_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enron_parse.filter_data('../data/interim/data_first_only_ALL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111044, 2)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='Subject',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There sre some level of reptitions throughout the body text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"ANNOUNCING\" A market that is Virtually UNTAPPED!!',\n",
       " 'Would YOU  like to learn more about a company that has  - A product that is virtually UNTAPPED!  - Is Still widely UNKNOWN!  - A product EVERYONE needs!  - A product OVER  80% of Europeans have!  - A product UNDER 2% of the US has!  - Cost less than a cup of coffee a day!  - YOUR comissions are PAID DAILY!!!  - And is growing faster than MICROSOFT.... yes MICROSOFT!!!  Then send a email and see for YOURSELF!  Information residual28@yahoo.com  ________________________________________________ DISCLAIMER: ======================================== NOTE: This e-mail is not Spam. You are receiving this e-mail because you have previously requested more info on a Business Opportunity or we have shared same opt-in or safe e-mail list or we have exchanged business opportunities in the past. If you are no longer interested in exchanging business opportunities, please click on the link below  and put REMOVE ME in the subject line..  To be removed residual27@yahoo.com')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-6]['Subject'], df.iloc[-6]['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"ANNOUNCING\" a market that is Virtually UNTAPPED!!',\n",
       " 'Would YOU  like to learn more about a company that has  - A product that is virtually UNTAPPED!  - Is Still widely UNKNOWN!  - A product EVERYONE needs!  - A product OVER  80% of Europeans have!  - A product UNDER 2% of the US has!  - Cost less than a cup of coffee a day!  - YOUR comissions are PAID DAILY!!!  - And is growing faster than MICROSOFT.... yes MICROSOFT!!!  Then send a email for more information and see for YOURSELF!  residual26@yahoo.com  ________________________________________________ DISCLAIMER: ======================================== NOTE: This e-mail is not Spam. You are receiving this e-mail because you have previously requested more info on a Business Opportunity or we have shared same opt-in or safe e-mail list or we have exchanged business opportunities in the past. If you are no longer interested in exchanging business opportunities, please send to the email below residual11@yahoo.com')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-7]['Subject'], df.iloc[-7]['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/interim/data_111044.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              hello'"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%19s'%'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('Old-Time / Historic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/interim/data_111044.json', 'w') as f:\n",
    "#     f.write(df.to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_111044 = pd.read_csv('../data/interim/data_111044.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>~~~~~~~TOP-NOTCH Attorneys For PENNIES A Day ~...</td>\n",
       "      <td>You Can Receive Thousands of Dollars in Legal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zev-program Second Notice of Availability of M...</td>\n",
       "      <td>The Second Notice of Availability of Modified ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zev-program Second Notice</td>\n",
       "      <td>Greetings,  The Second Notice of Public Availa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zev-program California Fuel Cell Partnership R...</td>\n",
       "      <td>You are invited to attend or monitor live via ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zev-program 15-day regulatory changes</td>\n",
       "      <td>Greetings,  The Notice of Public Availability ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  \\\n",
       "0  ~~~~~~~TOP-NOTCH Attorneys For PENNIES A Day ~...   \n",
       "1  zev-program Second Notice of Availability of M...   \n",
       "2                          zev-program Second Notice   \n",
       "3  zev-program California Fuel Cell Partnership R...   \n",
       "4              zev-program 15-day regulatory changes   \n",
       "\n",
       "                                                Body  \n",
       "0  You Can Receive Thousands of Dollars in Legal ...  \n",
       "1  The Second Notice of Availability of Modified ...  \n",
       "2  Greetings,  The Second Notice of Public Availa...  \n",
       "3  You are invited to attend or monitor live via ...  \n",
       "4  Greetings,  The Notice of Public Availability ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_111044.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample a smaller set of data for model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_df = df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_df.to_csv('../data/interim/data_111044_1000.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/interim/data_111044_1000.json', 'w') as f:\n",
    "#     f.write(small_df.to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving as txt file?\n",
    "# data_small = pd.read_csv('../data/interim/data_111044_1000.txt', sep='\\t', names=['Body','Subject'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read train, val, test split\n",
    "- return body, subject pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/interim/111044_1000/'\n",
    "LARGE_DATA_PATH = '../data/interim/111044/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = enron_parse.read_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenized data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets, vocab\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_glove_vector(max_vectors):\n",
    "    raw_vocab = vocab.GloVe(max_vectors=max_vectors)\n",
    "    raw_vocab.itos = ['<unk>', '<pad>', '<s>', '</s>'] + raw_vocab.itos\n",
    "    raw_vocab.stoi = defaultdict(vocab._default_unk_index)\n",
    "    raw_vocab.stoi.update({tok: i for i, tok in enumerate(raw_vocab.itos)})\n",
    "    emb_size = raw_vocab.vectors.size()[1]\n",
    "    zero = torch.zeros(2, emb_size)\n",
    "    vectors = torch.cat([zero, raw_vocab.vectors])\n",
    "    raw_vocab.vectors = vectors\n",
    "    return raw_vocab\n",
    "\n",
    "glove_vocab_modify = initialize_glove_vector(max_vectors=100000)\n",
    "# train.fields['x'].vocab = glove_vocab_modify\n",
    "# vocabulary = train.fields['x'].vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_senna_vector():\n",
    "    with open('senna_embed/words.lst' , 'r') as f:\n",
    "        itos = [line.rstrip('\\n') for line in f]\n",
    "    stoi = defaultdict()\n",
    "    counter = Counter(itos)\n",
    "    raw_vocab = vocab.Vocab(counter)\n",
    "    raw_vocab.itos = ['<unk>', '<pad>'] + itos\n",
    "    raw_vocab.stoi = defaultdict(vocab._default_unk_index)\n",
    "    raw_vocab.stoi.update({tok: i for i, tok in enumerate(raw_vocab.itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tokenizer:\n",
    "    def __init__(self):\n",
    "        self.stoi = {'<unk>':0, '<link>':1, '<pad>':2}\n",
    "    def tokenize(self, x):\n",
    "        return [i.split() for i in x]\n",
    "    def build_vocab(self, x_tokenized):\n",
    "        counter = Counter(np.concatenate(x_tokenized).flat)\n",
    "        raw_vocab = torchtext.vocab.Vocab(counter)\n",
    "        raw_vocab.itos = ['<unk>','<link>'] + raw_vocab.itos\n",
    "        raw_vocab.stoi = defaultdict(torchtext.vocab._default_unk_index)\n",
    "        raw_vocab.stoi.update({tok: i for i, tok in enumerate(raw_vocab.itos)})\n",
    "        return raw_vocab.stoi, raw_vocab.itos\n",
    "    def convert_tokens_to_ids(self, seq, vocab):\n",
    "        out = [None]*len(seq)\n",
    "        for i, tok in enumerate(seq):\n",
    "            if tok.startswith('http://'):\n",
    "                out[i] = 1\n",
    "#             if tok.\n",
    "            if tok in vocab:\n",
    "                out[i] = vocab.index(tok)\n",
    "            else:\n",
    "                out[i] = 0\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = data.get_tokenizer('spacy')\n",
    "\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "PAD_TOKEN = \"<pad>\"    \n",
    "SOS_TOKEN = \"<s>\"\n",
    "EOS_TOKEN = \"</s>\"\n",
    "LOWER = True\n",
    "\n",
    "# we include lengths to provide to the RNNs\n",
    "SRC = data.Field(tokenize=tokenizer, \n",
    "                      lower=True, include_lengths=True, batch_first=True, \n",
    "                      unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n",
    "TRG = data.Field(tokenize=tokenizer, \n",
    "                      lower=True, include_lengths=True, batch_first=True,\n",
    "                      unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n",
    "\n",
    "\n",
    "MAX_LEN = 500  # NOTE: we filter out a lot of sentences for speed\n",
    "trn_data_fields = [(\"src\", SRC), (\"trg\", TRG)]\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(path=f'{DATA_PATH}',\n",
    "                                 train='train.csv', validation='val.csv', test='test.csv',\n",
    "                                 format='csv', skip_header=True, fields=trn_data_fields, \n",
    "                                 filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and len(vars(x)['trg']) <= MAX_LEN)\n",
    "\n",
    "\n",
    "\n",
    "MIN_FREQ = 5  # NOTE: we limit the vocabulary to frequent words for speed\n",
    "SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)\n",
    "TRG.build_vocab(train_data.trg, min_freq=MIN_FREQ)\n",
    "\n",
    "PAD_INDEX = TRG.vocab.stoi[PAD_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.fields['src'].vocab = glove_vocab_modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.fields['trg'].vocab = glove_vocab_modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100002, 300])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.fields['trg'].vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(2, 10)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Embedding(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(100002, 300)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Embedding.from_pretrained(glove_vocab_modify.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.example.Example at 0x1a4bc513c8>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = data.BucketIterator(train_data, batch_size=20, train=True, \n",
    "                                 sort_within_batch=True, \n",
    "                                 sort_key=lambda x: (len(x.src), len(x.trg)), repeat=False,\n",
    "                                 device=DEVICE)\n",
    "valid_iter = data.Iterator(valid_data, batch_size=1, train=False, sort=False, repeat=False, \n",
    "                           device=DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
